{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1017Kosuke/About-me-/blob/Portfolio/lecture07_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI0CCRYGbsLX"
      },
      "source": [
        "# 第7回講義 宿題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhZjl_2gbsLf"
      },
      "source": [
        "### 課題\n",
        "RNNを用いてIMDbのsentiment analysisを実装してみましょう．\n",
        "\n",
        "ネットワークの形などに制限はとくになく，今回のLessonで扱った内容以外の工夫も組み込んでもらって構いません．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBcfs2VybsLj"
      },
      "source": [
        "### 目標値\n",
        "F値：0.85"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZj-U7SvbsLl"
      },
      "source": [
        "### ルール\n",
        "\n",
        "- **以下のセルで指定されている`x_train`, `t_train`以外の学習データは使わないでください．**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm9ZJX2TbsLo"
      },
      "source": [
        "### 提出方法\n",
        "- 2つのファイルを提出していただきます．\n",
        "  1. テストデータ `x_test` に対する予測ラベルを`submission_pred.csv`として保存し，Omnicampusの宿題から**「第7回 回帰結合型ニューラルネットワーク」を選択して**提出してください．\n",
        "  2. それに対応するpythonのコードを`submission_code.py`として保存し，**Omnicampusの宿題から「第7回 回帰結合型ニューラルネットワーク (code)」を選択して**提出してください．提出してください．pythonファイル自体の提出ではなく，「提出内容」の部分にコードをコピー&ペーストしてください．\n",
        "\n",
        "- なお，採点は1で行い，2はコードの確認用として利用します（成績優秀者はコード内容を公開させていただくかもしれません）．コードの内容を変更した場合は，**1と2の両方を提出し直してください**．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejdA6CESbsLs"
      },
      "source": [
        "### 評価方法\n",
        "\n",
        "- 予測ラベルの`t_test`に対するF値で評価します．\n",
        "- 即時採点しLeader Boardを更新します．（採点スケジュールは別アナウンス）\n",
        "- 締切時の点数を最終的な評価とします．\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyYaymAQ4Wey"
      },
      "source": [
        "### ドライブのマウント"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Szesnftz4a1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "259ee8d3-078b-4150-f2be-b726bcea9901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 作業ディレクトリを指定\n",
        "work_dir = '/content/drive/MyDrive/Colab Notebooks/DLBasics2025_colab/Lecture07'"
      ],
      "metadata": {
        "id": "jeR6ST382WcT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjSgBf1ibsLw"
      },
      "source": [
        "### データの読み込み（このセルは修正しないでください）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4X9ptijybsLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa8ac80-87e6-4d30-aa00-179949d9897c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "単語種数: 88587\n"
          ]
        }
      ],
      "source": [
        "!pip install portalocker\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "from typing import List, Union\n",
        "\n",
        "seed = 1234\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "\n",
        "# 学習データ\n",
        "x_train = np.load(work_dir + '/data/x_train.npy', allow_pickle=True)\n",
        "t_train = np.load(work_dir + '/data/t_train.npy', allow_pickle=True)\n",
        "\n",
        "# 検証データを取る\n",
        "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.2, random_state=seed)\n",
        "\n",
        "# テストデータ\n",
        "x_test = np.load(work_dir + '/data/x_test.npy', allow_pickle=True)\n",
        "\n",
        "\n",
        "def text_transform(text: List[int], max_length=256):\n",
        "    # <BOS>はすでに1で入っている．<EOS>は2とする．\n",
        "    text = text[:max_length - 1] + [2]\n",
        "\n",
        "    return text, len(text)\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, len_seq_list = [], [], []\n",
        "\n",
        "    for sample in batch:\n",
        "        if isinstance(sample, tuple):\n",
        "            label, text = sample\n",
        "\n",
        "            label_list.append(label)\n",
        "        else:\n",
        "            text = sample.copy()\n",
        "\n",
        "        text, len_seq = text_transform(text)\n",
        "        text_list.append(torch.tensor(text))\n",
        "        len_seq_list.append(len_seq)\n",
        "\n",
        "    # NOTE: 宿題用データセットでは<PAD>は3です．\n",
        "    return torch.tensor(label_list), pad_sequence(text_list, padding_value=3).T, torch.tensor(len_seq_list)\n",
        "\n",
        "\n",
        "word_num = np.concatenate(np.concatenate((x_train, x_test))).max() + 1\n",
        "print(f\"単語種数: {word_num}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_len = min(len(x) for x in x_train)\n",
        "print(min_len) # Max 7 tokens\n",
        "max_len = max(len(x) for x in x_train)\n",
        "print(max_len) # Min 2494 tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIQ-km5gkVB8",
        "outputId": "af845edd-995a-4902-b240-b44eafe8018a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "2494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (backbone = LSTM -> Attention)"
      ],
      "metadata": {
        "id": "2Y31ypAzt0bM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, t_train.shape, x_valid.shape, t_valid.shape, x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjA6ePA5esZ3",
        "outputId": "61135a21-ad8e-4b8c-8fd7-f1ed340e4009"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32000,), (32000,), (8000,), (8000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed(seed=1234):\n",
        "  torch.manual_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)"
      ],
      "metadata": {
        "id": "7PRRgV-pympm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIKgr01wbsL5"
      },
      "source": [
        "### 実装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WPhmbQtagOvH"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    [(t, x) for t, x in zip(t_train, x_train)],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_batch,\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    [(t, x) for t, x in zip(t_valid, x_valid)],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_batch,\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    x_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_batch,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "w6j2soNLbsL7"
      },
      "outputs": [],
      "source": [
        "def torch_log(x):\n",
        "    return torch.log(torch.clamp(x, min=1e-10))\n",
        "\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    def _init_(self,vocab_size,emb_dim):\n",
        "        super()._init_()\n",
        "        self.embedding_matrix = nn.Parameter(torch.randn(vocab_size,emb_dim),dtype=torch.float)\n",
        "    def forward(self,x):\n",
        "        return F.embedding(x,self.embedding_matrix)\n",
        "\n",
        "class BidirectionalLSTM(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        glorot = 6/(in_dim + hid_dim*2)\n",
        "\n",
        "        self.W_i = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_i = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_f = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_f = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_o = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_o = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_c = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_c = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "    def function(self, state_c, state_h, x):\n",
        "        i = torch.sigmoid(torch.matmul(torch.cat([state_h, x], dim=1), self.W_i) + self.b_i)  # WRITE ME\n",
        "        f = torch.sigmoid(torch.matmul(torch.cat([state_h, x], dim=1), self.W_f) + self.b_f)  # WRITE ME\n",
        "        o = torch.sigmoid(torch.matmul(torch.cat([state_h, x], dim=1), self.W_o) + self.b_o)  # WRITE ME\n",
        "        c = f*state_c + i*torch.tanh(torch.matmul(torch.cat([state_h, x], dim=1), self.W_c) + self.b_c)  # WRITE ME\n",
        "        h = o*torch.tanh(c)\n",
        "        return c, h\n",
        "    def forward(self, x, len_seq_max=0, init_state_c=None, init_state_h=None):\n",
        "        x = x.transpose(0, 1)  # 系列のバッチ処理のため、次元の順番を「系列、バッチ」の順に入れ替える\n",
        "        state_c = init_state_c\n",
        "        state_h = init_state_h\n",
        "        if init_state_c is None:  # 初期値を設定しない場合は0で初期化する\n",
        "            state_c = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
        "        if init_state_h is None:  # 初期値を設定しない場合は0で初期化する\n",
        "            state_h = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
        "\n",
        "        size = list(state_h.unsqueeze(0).size())\n",
        "        size[0] = 0\n",
        "        output = torch.empty(size, dtype=torch.float).to(x.device)  # 一旦空テンソルを定義して順次出力を追加する\n",
        "\n",
        "        if len_seq_max == 0:\n",
        "            len_seq_max = x.size(0)\n",
        "        for i in range(len_seq_max):\n",
        "            state_c, state_h = self.function(state_c, state_h, x[i])\n",
        "            output = torch.cat([output, state_h.unsqueeze(0)])  # 出力系列の追加\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BidirectionalLSTM(nn.Module):\n",
        "    def __init__(self, word_num, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        # 順方向と逆方向のLSTMを用意する\n",
        "        self.emb = nn.Embedding(word_num, emb_dim)\n",
        "        self.forward_lstm = nn.LSTM(emb_dim, hid_dim, 1, batch_first=True)\n",
        "        self.backward_lstm = nn.LSTM(emb_dim, hid_dim, 1, batch_first=True)\n",
        "        self.linear = nn.Linear(hid_dim*2, 1)  # ForwardとBackwardの出力をconcatしたものを渡すので2倍\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
        "        h = self.emb(x)  # (batch_size, seq_length, emb_dim)\n",
        "\n",
        "        # Backwardにはシークエンスを反転して渡す\n",
        "        if len_seq_max > 0:\n",
        "            h1, _ = self.forward_lstm(h[:, 0:len_seq_max, :], init_state)\n",
        "            h2, _ = self.backward_lstm(torch.flip(h[:, 0:len_seq_max, :], dims=[1]), init_state)\n",
        "        else:\n",
        "            h1, _ = self.forward_lstm(h, init_state)  # (batch_size, seq_length, hid_dim)\n",
        "            h2, _ = self.backward_lstm(torch.flip(h, dims=[1]), init_state)  # (batch_size, seq_length, hid_dim)\n",
        "        # Backwardから返ってきたものを再び反転する\n",
        "        h2 = torch.flip(h2, dims=[1])\n",
        "\n",
        "        # ForwardとBackwardの出力を結合\n",
        "        h = torch.cat([h1, h2], dim=2).transpose(0, 1)\n",
        "\n",
        "        if len_seq is not None:\n",
        "            h = h[len_seq - 1, list(range(len(x))), :]\n",
        "        else:\n",
        "            h = h[-1]\n",
        "\n",
        "        y = self.linear(h)\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "9oMBBydx-FqL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init_(self,)"
      ],
      "metadata": {
        "id": "KFVf2vWnzi98"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w3yjqqCl_Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6864b16-62d0-4626-8a88-72da8e18f2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0, Train Loss: 0.694, Valid Loss: 0.695, Validation F1: 0.478\n",
            "EPOCH: 1, Train Loss: 0.694, Valid Loss: 0.695, Validation F1: 0.478\n"
          ]
        }
      ],
      "source": [
        "emb_dim = 100\n",
        "hid_dim = 50\n",
        "n_epochs = 10\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "net = BidirectionalLSTM(word_num, emb_dim, hid_dim)\n",
        "net.to(device)\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    losses_train = []\n",
        "    losses_valid = []\n",
        "\n",
        "    net.train()\n",
        "    n_train = 0\n",
        "    acc_train = 0\n",
        "    for label, line, len_seq in train_dataloader:\n",
        "        net.zero_grad()\n",
        "        t = label.to(device)\n",
        "        x = line.to(device)\n",
        "        len_seq = len_seq.to(device)\n",
        "\n",
        "        h = net(x,torch.max(len_seq),len_seq)\n",
        "        y = torch.sigmoid(h).squeeze()\n",
        "        loss = -torch.mean(t*torch_log(y) + (1-t)*torch_log(1-y))\n",
        "        loss.backward()\n",
        "\n",
        "        # 勾配を絶対値1.0でクリッピングする\n",
        "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
        "        losses_train.append(loss.tolist())\n",
        "\n",
        "        n_train += t.size()[0]\n",
        "\n",
        "    # Valid\n",
        "    t_valid = []\n",
        "    y_pred = []\n",
        "    net.eval()\n",
        "    for label, line, len_seq in valid_dataloader:\n",
        "            t = label.to(device)  # テンソルをGPUに移動\n",
        "            x = line.to(device) # ( batch, time )\n",
        "            len_seq.to(device)\n",
        "\n",
        "            h = net(x, torch.max(len_seq), len_seq)\n",
        "            y = torch.sigmoid(h).squeeze()\n",
        "\n",
        "            loss = -torch.mean(t*torch_log(y) + (1 - t)*torch_log(1 - y))\n",
        "\n",
        "            pred = y.round().squeeze()\n",
        "\n",
        "            t_valid.extend(t.tolist())\n",
        "            y_pred.extend(pred.tolist())\n",
        "\n",
        "            losses_valid.append(loss.tolist())\n",
        "\n",
        "    print('EPOCH: {}, Train Loss: {:.3f}, Valid Loss: {:.3f}, Validation F1: {:.3f}'.format(\n",
        "        epoch,\n",
        "        np.mean(losses_train),\n",
        "        np.mean(losses_valid),\n",
        "        f1_score(t_valid, y_pred, average='macro')\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQ8xtUcHj6IR"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "\n",
        "y_pred = []\n",
        "for _, line, len_seq in test_dataloader:\n",
        "\n",
        "    x = line.to(device)\n",
        "    len_seq.to(device)\n",
        "\n",
        "    h = net(x, torch.max(len_seq), len_seq)\n",
        "    y = torch.sigmoid(h).squeeze()\n",
        "\n",
        "    pred = y.round().squeeze()  # 0.5以上の値を持つ要素を正ラベルと予測する\n",
        "\n",
        "    y_pred.extend(pred.tolist())\n",
        "\n",
        "\n",
        "submission = pd.Series(y_pred, name='label')\n",
        "submission.to_csv(work_dir + '/Lecture07/submission_pred.csv', header=True, index_label='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-MRCNboHZNd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}